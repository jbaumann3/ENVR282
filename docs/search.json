[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ENVR 282",
    "section": "",
    "text": "Welcome to ENVR 282: Research Methods in Environmental Science."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "getting_started.html",
    "href": "getting_started.html",
    "title": "Lab 0: Getting Started",
    "section": "",
    "text": "IN THIS TUTORIAL YOU WILL LEARN:\n1.) How to access and/or install R and RStudio\n2.) How to navigate RStudio\n3.) How to set and change the working directory\n4.) How to setup an RStudio Project"
  },
  {
    "objectID": "getting_started.html#how-to-set-the-working-directory",
    "href": "getting_started.html#how-to-set-the-working-directory",
    "title": "Lab 0: Getting Started",
    "section": "How to SET the working directory",
    "text": "How to SET the working directory\n1.) Using the “Files” tab to set manually: a.) Using the ‘…’ in the ‘Files’ tab you can select any directory (folder) on your computer. You can also set a google drive, box, dropbox, or other shared folder as your working directory if you’d like (as long as you are syncing a folder between the cloud and your computer – ASK me if you have questions about this!) b.) Once you navigate to a directory you still need to SET IT as your working directory. You do this in the “More” cog– select “Set as working directory”\n2.) Set working directory with code: We use the ‘setwd()’ function for this. Below is an example. You will need to replace the path details with your own!\n\nsetwd(\"C:/Users/Justin Baumann/Teaching/Bates College/ENV 282 - Research Design in Env Sci\")"
  },
  {
    "objectID": "getting_started.html#to-make-a-quarto-document",
    "href": "getting_started.html#to-make-a-quarto-document",
    "title": "Lab 0: Getting Started",
    "section": "To make a Quarto document",
    "text": "To make a Quarto document\nclick file -&gt; new file -&gt; Quarto document / Complete the pop up prompts and then wait for the document to load. / We want to replace the top bit (our YAML header, everything between the two lines that contains just — at the top) with the following (use your name and title!)\n\n---\ntitle: \"Lab 1: Intro to R, RStudio, and Quarto\"\nauthor: \"Justin Baumann\"\nformat: \n  html:\n    toc: true\n  pdf:\n    toc: true\n    number-sections: true\n    colorlinks: true\neditor: visual\n---"
  },
  {
    "objectID": "getting_started.html#formatting-text",
    "href": "getting_started.html#formatting-text",
    "title": "Lab 0: Getting Started",
    "section": "Formatting text",
    "text": "Formatting text\nUnlike in a regular R script, using the ‘#’ at the start of a line will not comment that line out. Instead, you can type as you would normally in an R Markdown (Rmd) document. We can format our text in the following ways:\n Bold: ‘’ on either end of a word, phrase, or line will make it bold! this is in bold** =’‘this is in bold’’ without the quotes around the **\n\nLine breaks: DO you want text to be on different lines? Insert a ’’ at the end of a line to make a line break!"
  },
  {
    "objectID": "getting_started.html#making-a-code-chunk",
    "href": "getting_started.html#making-a-code-chunk",
    "title": "Lab 0: Getting Started",
    "section": "Making a code chunk",
    "text": "Making a code chunk\nSince qmd documents are text based, we need to tell RStudio when we want to actually include code. To do this, we will insert a code chunk. To insert a code chunk:\n\n1.) Use the keyboard shortcut ‘ctrl’+‘alt’+‘i’ (PC) or ‘cmd’+‘alt’+‘i’ (Mac) to insert a code chunk.\n\n2.) Navigate to the top bar (of the top left quadrant of RStudio), find “+c” at the right of the bar to insert an R code chink.\nOnce you have a code chunk inserted you will notice that the background of the chunk is gray instead of your default background color (white or black if you are in dark mode)\n\n#this is an example code chunk\n\n# Using '#' at the start of a line indicates a comment, which is not runnable code!"
  },
  {
    "objectID": "getting_started.html#rendering-your-report",
    "href": "getting_started.html#rendering-your-report",
    "title": "Lab 0: Getting Started",
    "section": "Rendering your report",
    "text": "Rendering your report\nTo Visualize what your report will look like, click the ‘visual’ tab in the top bar (on the left). Note that if you do this, it CAN change your code–so be careful. You can also use the GUI to alter your report in the visual tab. This provides a nice alternative to the code based formatting options in the ‘source’ tab.\n\nTo actually render into an html or pdf document, you must click “Render”. You can use the arrow to the right of “Render” to choose render to html or render to pdf. I suggest using HTML most of the time but you can use pdf if you prefer. You will need to successfully Render your quarto document into an html or pdf report in order to turn in your labs!"
  },
  {
    "objectID": "images/Lab 4_ T-tests.html",
    "href": "images/Lab 4_ T-tests.html",
    "title": "Lab 4: T-tests",
    "section": "",
    "text": "IN THIS TUTORIAL YOU WILL LEARN:  1.) The theory behind a T-test and how to perform one  2.) Practice data preparation skills  3.) How to pair graphs and stats to test hypotheses"
  },
  {
    "objectID": "images/Lab 4_ T-tests.html#t-test-theory",
    "href": "images/Lab 4_ T-tests.html#t-test-theory",
    "title": "Lab 4: T-tests",
    "section": "T-test theory",
    "text": "T-test theory\nThe t-test (or students’ t-test) is a basic statistical test used to assess whether or not the means of two groups are different from one another. In this test, the null hypothesis is that the two means are equal (or that there is no difference between the two means).\nA t-test should only be used if the following assumptions are met:  1.) the two distributions whose means we are comparing must be normally distributed  2.) The variances of the two groups must be equal \nGenerate example data\n\niris2&lt;-iris %&gt;%\n  filter(Species != 'setosa') %&gt;%\n  droplevels() #removes the empty levels so when we check levels below we only get the ones that are still in the data!\n\n#check levels to make sure we only have 2 species!\nhead(iris2)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width    Species\n1          7.0         3.2          4.7         1.4 versicolor\n2          6.4         3.2          4.5         1.5 versicolor\n3          6.9         3.1          4.9         1.5 versicolor\n4          5.5         2.3          4.0         1.3 versicolor\n5          6.5         2.8          4.6         1.5 versicolor\n6          5.7         2.8          4.5         1.3 versicolor\n\nlevels(iris2$Species)\n\n[1] \"versicolor\" \"virginica\" \n\n\nWe will use these data for our examples today. T-test requires only 2 groups/populations. We will assess the alternative hypothesis that one of our numerical variables (sepal length, sepal width, petal length, or petal width) differs by species.\nBut first, we must test our assumptions"
  },
  {
    "objectID": "images/Lab 4_ T-tests.html#assumption-1.-assessing-normality",
    "href": "images/Lab 4_ T-tests.html#assumption-1.-assessing-normality",
    "title": "Lab 4: T-tests",
    "section": "Assumption 1.) Assessing normality",
    "text": "Assumption 1.) Assessing normality\nMethod 1: the Shapiro-Wilk Test If p &lt; 0.05 then the distribution is significantly different from normal.\nStep 1: we need to create separate data frames for each species to assess normality of each variable by species!\n\nversi&lt;-iris2 %&gt;%\n  filter(Species=='versicolor') %&gt;%\n  droplevels()\n\nvirg&lt;-iris2 %&gt;%\n  filter(Species=='virginica') %&gt;%\n  droplevels()\n\n\nStep 2: We can run our shapiro-wilk tests on each variable if we’d like\n\nshapiro.test(versi$Petal.Length) #this is normally distributed\n\n\n    Shapiro-Wilk normality test\n\ndata:  versi$Petal.Length\nW = 0.966, p-value = 0.1585\n\nshapiro.test(versi$Petal.Width) # this is not\n\n\n    Shapiro-Wilk normality test\n\ndata:  versi$Petal.Width\nW = 0.94763, p-value = 0.02728\n\nshapiro.test(versi$Sepal.Length) #normal\n\n\n    Shapiro-Wilk normality test\n\ndata:  versi$Sepal.Length\nW = 0.97784, p-value = 0.4647\n\nshapiro.test(versi$Sepal.Width) #normal\n\n\n    Shapiro-Wilk normality test\n\ndata:  versi$Sepal.Width\nW = 0.97413, p-value = 0.338\n\nshapiro.test(virg$Petal.Length) #normal\n\n\n    Shapiro-Wilk normality test\n\ndata:  virg$Petal.Length\nW = 0.96219, p-value = 0.1098\n\nshapiro.test(virg$Petal.Width) #normal\n\n\n    Shapiro-Wilk normality test\n\ndata:  virg$Petal.Width\nW = 0.95977, p-value = 0.08695\n\nshapiro.test(virg$Sepal.Length) #normal\n\n\n    Shapiro-Wilk normality test\n\ndata:  virg$Sepal.Length\nW = 0.97118, p-value = 0.2583\n\nshapiro.test(virg$Sepal.Width) #normal\n\n\n    Shapiro-Wilk normality test\n\ndata:  virg$Sepal.Width\nW = 0.96739, p-value = 0.1809\n\n\n Method 2: Visualization\nExplore the following visualizations. Do you see clear evidence of normality?\n\na1&lt;-ggplot(data=iris2, aes(Petal.Length, fill=Species))+\n  geom_histogram(binwidth = 0.3)+ \n  facet_wrap(~Species)+\n  theme_classic()+\n  scale_fill_aaas()\n\na2&lt;-ggplot(data=iris2, aes(x=Petal.Length, y=Species, fill=Species))+\n  geom_density_ridges()+ #makes a smooth density curve instead of a histogram!\n  theme_classic()+\n  scale_fill_aaas()\n\na1/a2 #compare the visualizations (they are of the same data)- do we see normality here?\n\nPicking joint bandwidth of 0.206\n\n\n\n\n\n\nb1&lt;-ggplot(data=iris2, aes(Petal.Width, fill=Species))+\n  geom_histogram(binwidth = 0.3)+ \n  facet_wrap(~Species)+\n  theme_classic()+\n  scale_fill_aaas()\n\nb2&lt;-ggplot(data=iris2, aes(x=Petal.Width, y=Species, fill=Species))+\n  geom_density_ridges()+ #makes a smooth density curve instead of a histogram!\n  theme_classic()+\n  scale_fill_aaas()\n\nb1/b2 #compare the visualizations (they are of the same data)- do we see normality here?\n\nPicking joint bandwidth of 0.0972\n\n\n\n\n\n\nc1&lt;-ggplot(data=iris2, aes(Sepal.Width, fill=Species))+\n  geom_histogram(binwidth = 0.3)+ \n  facet_wrap(~Species)+\n  theme_classic()+\n  scale_fill_aaas()\n\nc2&lt;-ggplot(data=iris2, aes(x=Sepal.Width, y=Species, fill=Species))+\n  geom_density_ridges()+ #makes a smooth density curve instead of a histogram!\n  theme_classic()+\n  scale_fill_aaas()\n\nc1/c2 #compare the visualizations (they are of the same data)- do we see normality here?\n\nPicking joint bandwidth of 0.122\n\n\n\n\n\n\nd1&lt;-ggplot(data=iris2, aes(Sepal.Length, fill=Species))+\n  geom_histogram(binwidth = 0.3)+ \n  facet_wrap(~Species)+\n  theme_classic()+\n  scale_fill_aaas()\n\nd2&lt;-ggplot(data=iris2, aes(x=Sepal.Length, y=Species, fill=Species))+\n  geom_density_ridges()+ #makes a smooth density curve instead of a histogram!\n  theme_classic()+\n  scale_fill_aaas()\n\nd1/d2 #compare the visualizations (they are of the same data)- do we see normality here?\n\nPicking joint bandwidth of 0.21"
  },
  {
    "objectID": "images/Lab 4_ T-tests.html#assumption-2.-assessing-equal-variance",
    "href": "images/Lab 4_ T-tests.html#assumption-2.-assessing-equal-variance",
    "title": "Lab 4: T-tests",
    "section": "Assumption 2.) Assessing equal variance",
    "text": "Assumption 2.) Assessing equal variance\nAKA homogeneity of variance \nMethods 1: F-test We will use the F-Test to compare the variance of two populations. This can only be used with 2 populations and is thus only useful when we run a t-test.\nH0 for an F-test is: The variances of the two groups are equal.  Ha: The variances are different  p&lt;0.05 allows us to reject the null (H0) and suggests that the variances are different   note: The F-test assumes our data are already normal! You should not run it on non-normal data\n\n#we use var.test to run an F-test\nf1&lt;- var.test(Petal.Length ~ Species, data=iris2)\nf1 # p&gt;0.05, so we fail to reject H0 (the variances are likely equal)\n\n\n    F test to compare two variances\n\ndata:  Petal.Length by Species\nF = 0.72497, num df = 49, denom df = 49, p-value = 0.2637\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.411402 1.277530\nsample estimates:\nratio of variances \n         0.7249678 \n\nf2&lt;- var.test(Petal.Width ~ Species, data=iris2)\nf2 # p&lt;0.05, so we reject H0 (variances are likely different)\n\n\n    F test to compare two variances\n\ndata:  Petal.Width by Species\nF = 0.51842, num df = 49, denom df = 49, p-value = 0.02335\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.2941935 0.9135614\nsample estimates:\nratio of variances \n         0.5184243 \n\nf3&lt;- var.test(Sepal.Length ~ Species, data=iris2)\nf3 # p&gt;0.05, so we fail to reject H0 (the variances are likely equal)\n\n\n    F test to compare two variances\n\ndata:  Sepal.Length by Species\nF = 0.65893, num df = 49, denom df = 49, p-value = 0.1478\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.3739257 1.1611546\nsample estimates:\nratio of variances \n         0.6589276 \n\nf4&lt;- var.test(Sepal.Width ~ Species, data=iris2)\nf4 # p&gt;0.05, so we fail to reject H0 (the variances are likely equal)\n\n\n    F test to compare two variances\n\ndata:  Sepal.Width by Species\nF = 0.94678, num df = 49, denom df = 49, p-value = 0.849\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.5372773 1.6684117\nsample estimates:\nratio of variances \n         0.9467839 \n\n\n Method 2: Levene Test  A more flexible test of homogeneity of variance is the Levene Test. It can be used to compare the variance of many populations (not just 2) and is more flexible than the F-test, so it can be used even if the normality assumption is violated.  this is the most commonly used test for homogeneity of variance  leveneTest() is in the car package in R! \nN0: Variances of all populationos are equal  p&lt;0.05 allows us to reject H0\n\nl1&lt;- leveneTest(Petal.Length ~ Species, data=iris2)\nl1 # p&gt;0.05, so we fail to reject H0 (the variances are likely equal)\n\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value Pr(&gt;F)\ngroup  1  1.0674 0.3041\n      98               \n\nl2&lt;- leveneTest(Petal.Width ~ Species, data=iris2)\nl2 # p&lt;0.05, so we reject H0 (variances are likely different)\n\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value  Pr(&gt;F)  \ngroup  1  6.5455 0.01205 *\n      98                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nl3&lt;- leveneTest(Sepal.Length ~ Species, data=iris2)\nl3 # p&gt;0.05, so we fail to reject H0 (the variances are likely equal)\n\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value Pr(&gt;F)\ngroup  1  1.0245 0.3139\n      98               \n\nl4&lt;- leveneTest(Sepal.Width ~ Species, data=iris2)\nl4 # p&gt;0.05, so we fail to reject H0 (the variances are likely equal)\n\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value Pr(&gt;F)\ngroup  1  0.0873 0.7683\n      98               \n\n\n Method 3: Visualization  Since p-values are more like guidelines, we also want to visualize our data to assess homogeniety of variance. We can do that in several ways. You might already have some ideas about this! In general, it seems smart to display the raw data as points and as boxplots. Let’s start there!\n\nv1.1&lt;-ggplot(data=iris2, aes(x=Species, y=Petal.Length, color=Species))+\n  geom_point()+\n  theme_classic()+\n  scale_color_aaas()\n\nv1.2&lt;-ggplot(data=iris2, aes(x=Species, y=Petal.Length, color=Species))+\n  geom_boxplot()+\n  theme_classic()+\n  scale_color_aaas()\n\nv1.1+v1.2\n\n\n\n\n\nv2.1&lt;-ggplot(data=iris2, aes(x=Species, y=Petal.Width, color=Species))+\n  geom_point()+\n  theme_classic()+\n  scale_color_aaas()\n\nv2.2&lt;-ggplot(data=iris2, aes(x=Species, y=Petal.Width, color=Species))+\n  geom_boxplot()+\n  theme_classic()+\n  scale_color_aaas()\n\nv2.1+v2.2\n\n\n\n\n\nv3.1&lt;-ggplot(data=iris2, aes(x=Species, y=Sepal.Width, color=Species))+\n  geom_point()+\n  theme_classic()+\n  scale_color_aaas()\n\nv3.2&lt;-ggplot(data=iris2, aes(x=Species, y=Sepal.Width, color=Species))+\n  geom_boxplot()+\n  theme_classic()+\n  scale_color_aaas()\n\nv3.1+v3.2\n\n\n\n\n\nv4.1&lt;-ggplot(data=iris2, aes(x=Species, y=Sepal.Length, color=Species))+\n  geom_point()+\n  theme_classic()+\n  scale_color_aaas()\n\nv4.2&lt;-ggplot(data=iris2, aes(x=Species, y=Sepal.Length, color=Species))+\n  geom_boxplot()+\n  theme_classic()+\n  scale_color_aaas()\n\nv4.1+v4.2"
  },
  {
    "objectID": "images/Lab 4_ T-tests.html#when-can-we-ignore-assumptions",
    "href": "images/Lab 4_ T-tests.html#when-can-we-ignore-assumptions",
    "title": "Lab 4: T-tests",
    "section": "When can we ignore assumptions?",
    "text": "When can we ignore assumptions?\nWe can if our sample sizes are large. If n is small, we should not ignore this assumption. There are alternatives to dealing with normality that we can discuss in the ANOVA section (such as transforming the data)\nFor more info on that\nWe can also ignore the equal variance requirement if we use the Welch t-test (default in R)"
  },
  {
    "objectID": "images/Lab 4_ T-tests.html#a-basic-t-test-in-r",
    "href": "images/Lab 4_ T-tests.html#a-basic-t-test-in-r",
    "title": "Lab 4: T-tests",
    "section": "A basic T-test in R",
    "text": "A basic T-test in R\nFinally, let’s do some T-tests! \nH0: No difference between the means of the 2 populations p&lt;0.05 allows us to reject this H0 (indicating a likely difference)\nStep 1: Calculate means and error and plot!\n\nmeaniris&lt;-iris2 %&gt;%\n  group_by(Species) %&gt;%\n  summarize(meanpl=mean(Petal.Length), sdpl=sd(Petal.Length), n=n(), sepl=sdpl/sqrt(n), meanpw=mean(Petal.Width), sdpw=sd(Petal.Width), n=n(), sepw=sdpw/sqrt(n), meansl=mean(Sepal.Length), sdsl=sd(Sepal.Length), n=n(), sesl=sdpl/sqrt(n), meansw=mean(Sepal.Width), sdsw=sd(Sepal.Width), n=n(), sesw=sdsw/sqrt(n))\n\nmeaniris\n\n# A tibble: 2 × 14\n  Species    meanpl  sdpl     n   sepl meanpw  sdpw   sepw meansl  sdsl   sesl\n  &lt;fct&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 versicolor   4.26 0.470    50 0.0665   1.33 0.198 0.0280   5.94 0.516 0.0665\n2 virginica    5.55 0.552    50 0.0780   2.03 0.275 0.0388   6.59 0.636 0.0780\n# ℹ 3 more variables: meansw &lt;dbl&gt;, sdsw &lt;dbl&gt;, sesw &lt;dbl&gt;\n\n\n\n\np1&lt;-ggplot(meaniris, aes(x=Species, y=meanpl, color=Species))+\n  geom_point()+\n  geom_errorbar(aes(x=Species, ymin=meanpl-sepl, ymax=meanpl+sepl), width=0.2)+\n  scale_color_aaas()+\n  theme_classic()+\n  labs(title='Petal Length')\n\np2&lt;-ggplot(meaniris, aes(x=Species, y=meanpw, color=Species))+\n  geom_point()+\n  geom_errorbar(aes(x=Species, ymin=meanpw-sepw, ymax=meanpw+sepw), width=0.2)+\n  scale_color_aaas()+\n  theme_classic()+\n  labs(title='Petal Width')\n\np3&lt;-ggplot(meaniris, aes(x=Species, y=meansl, color=Species))+\n  geom_point()+\n  geom_errorbar(aes(x=Species, ymin=meansl-sesl, ymax=meansl+sesl), width=0.2)+\n  scale_color_aaas()+\n  theme_classic()+\n  labs(title='Sepal Length')\n\np4&lt;-ggplot(meaniris, aes(x=Species, y=meansw, color=Species))+\n  geom_point()+\n  geom_errorbar(aes(x=Species, ymin=meansw-sesw, ymax=meansw+sesw), width=0.2)+\n  scale_color_aaas()+\n  theme_classic()+\n  labs(title='Sepal Width')\n\n(p1+p2)/(p3+p4)\n\n\n\n\nDoes Petal Length differ by species?\n\nt1&lt;-t.test(data=iris2, Petal.Length~Species, alternative='two.sided', var.equal=FALSE) #two.sided and var.equal= FALSE are default, so we don't have to list them. BUt, we can also change them (as I will show later)\n\nt1 #p&lt;0.05 suggests that there is a significant difference in petal length between species\n\n\n    Welch Two Sample t-test\n\ndata:  Petal.Length by Species\nt = -12.604, df = 95.57, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group versicolor and group virginica is not equal to 0\n95 percent confidence interval:\n -1.49549 -1.08851\nsample estimates:\nmean in group versicolor  mean in group virginica \n                   4.260                    5.552 \n\n\n Our p&lt;0.05 suggests that there is a significant effect of species on petal length (petal length differs by species). BUT, do we get a clear explanation of which group is higher or lower? Look at the Welch T-test output and you can see the means! You can also use the graph we made to visualize this!\nDoes Petal Width differ by species?\n\nt2&lt;-t.test(data=iris2, Petal.Width~Species, alternative='two.sided', var.equal=FALSE) #two.sided and var.equal= FALSE are default, so we don't have to list them. BUt, we can also change them (as I will show later)\n\nt2\n\n\n    Welch Two Sample t-test\n\ndata:  Petal.Width by Species\nt = -14.625, df = 89.043, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group versicolor and group virginica is not equal to 0\n95 percent confidence interval:\n -0.7951002 -0.6048998\nsample estimates:\nmean in group versicolor  mean in group virginica \n                   1.326                    2.026 \n\n\n Does Sepal Width differ between species?\n\nt3&lt;-t.test(data=iris2, Sepal.Width~Species, alternative='two.sided', var.equal=FALSE) #two.sided and var.equal= FALSE are default, so we don't have to list them. BUt, we can also change them (as I will show later)\n\nt3\n\n\n    Welch Two Sample t-test\n\ndata:  Sepal.Width by Species\nt = -3.2058, df = 97.927, p-value = 0.001819\nalternative hypothesis: true difference in means between group versicolor and group virginica is not equal to 0\n95 percent confidence interval:\n -0.33028364 -0.07771636\nsample estimates:\nmean in group versicolor  mean in group virginica \n                   2.770                    2.974 \n\n\n Does Sepal Length differ between species?\n\nt4&lt;-t.test(data=iris2, Sepal.Length~Species, alternative='two.sided', var.equal=FALSE) #two.sided and var.equal= FALSE are default, so we don't have to list them. BUt, we can also change them (as I will show later)\n\nt4\n\n\n    Welch Two Sample t-test\n\ndata:  Sepal.Length by Species\nt = -5.6292, df = 94.025, p-value = 1.866e-07\nalternative hypothesis: true difference in means between group versicolor and group virginica is not equal to 0\n95 percent confidence interval:\n -0.8819731 -0.4220269\nsample estimates:\nmean in group versicolor  mean in group virginica \n                   5.936                    6.588 \n\n\nSO, when is a t-test actually useful and when isn’t it? We use a T-test ONLY when we want to compare two means / two populations. If we have more than 2 groups, a T-test is not appropriate! Instead, we need to use an analysis of variance (ANOVA) or possibly something more complex!"
  }
]